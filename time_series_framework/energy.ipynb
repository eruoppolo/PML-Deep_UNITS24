{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy dataset\n",
    "\n",
    "The dataset contains electricity service data of the state of Victoria, Australia, of 2016 days between 1 January 2015 and 6 October 2020. The 2016 rows are described by 14 features:\n",
    "\n",
    "- **date**: `datetime`, the date of the recording\n",
    "- **demand**: `float`, total daily electricity demand in MWh\n",
    "- **RRP**: `float`, recommended retail price in AUD$ / MWh\n",
    "- **demand_pos_RRP**: `float`, total daily demand at positive RRP in MWh\n",
    "- **RRP_positive**: `float`, averaged positive RRP, weighted by the corresponding intraday demand in AUD$ / MWh\n",
    "- **demand_neg_RRP**: `float`, total daily demand at negative RRP in MWh\n",
    "- **RRP_negative**: `float`, average negative RRP, weighted by the corresponding intraday demand in AUD$ / MWh\n",
    "- **frac_at_neg_RRP**: `float`, fraction of the day when the demand was traded at negative RRP\n",
    "- **min_temperature**: `float`, minimum temperature during the day in Celsius\n",
    "- **max_temperature**: `float`, maximum temperature during the day in Celsius\n",
    "- **solar_exposure**: `float`, total daily sunlight energy in MJ/m²\n",
    "- **rainfall**: `float`, daily rainfall in mm\n",
    "- **school_day**: `boolean`, if students were at school on that day\n",
    "- **holiday**: `boolean`, if the day was a state or national holiday\n",
    "\n",
    "Some of them have been removed since DistilGPT-2 can manage only a reduced sequence of tokens, thus we removed some information, keeping only:\n",
    "\n",
    "- **date**\n",
    "- **demand**\n",
    "- **RRP**\n",
    "- **min_temperature**\n",
    "- **max_temperature**\n",
    "- **solar_exposure**\n",
    "- **school_day**\n",
    "\n",
    "The data has been preprocessed to respect the requirements needed for training the model, mainly dropping null values and dividing the time stamp into separated columns for each day, month and year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from statsmodels.tsa.stattools import acf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Real_Datasets/complete_dataset.csv')\n",
    "df = df.round(2)\n",
    "df.dropna(inplace=True)\n",
    "df.drop(['demand_pos_RRP', 'RRP_positive', 'RRP_positive', 'demand_neg_RRP', 'RRP_negative', 'frac_at_neg_RRP', 'rainfall', 'holiday'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertdate(df, date_column):\n",
    " \n",
    "    df[date_column] = pd.to_datetime(df[date_column], format='%Y-%m-%d')\n",
    "    \n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    df_filtered['Day']=df_filtered['date'].dt.day\n",
    "    df_filtered['Month']=df_filtered['date'].dt.month\n",
    "    df_filtered['Year']=df_filtered['date'].dt.year\n",
    "\n",
    "    df_filtered.drop(['date'], axis=1, inplace=True)\n",
    "    \n",
    "    df_filtered = df_filtered[[ 'Day', 'Month','Year','demand', 'RRP', 'min_temperature', 'max_temperature','solar_exposure', 'school_day']]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = convertdate(df, 'date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filtered.to_csv('energy_prep_c.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data import\n",
    "\n",
    "The dataset so preprocessed has been used to train the generative model. After that the synthetic data are here imported and preprocessed. Since the generation could not always work fine, the data are sometimes misgenerated in wrong format or completely out of bounds (for instance a temperature of 10k ºC), they could not have physical sense (as for instance min_temp>max_temp) or even not generated. Thus the first thing done here is to convert, if needed, the data in the original format, remove the missing values and the values somehow out of the original values ranges, ensuring that these are relxed to admit values out of the proper ranges but still significative for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin = pd.read_csv('window_datasets/energy_window.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin.rename(columns={'MonthDay': 'Day'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin['RRP'] = pd.to_numeric( df_sin['RRP'], errors='coerce')\n",
    "df_sin['demand'] = pd.to_numeric( df_sin['demand'], errors='coerce')\n",
    "df_sin['min_temperature'] = pd.to_numeric( df_sin['min_temperature'], errors='coerce')\n",
    "df_sin['max_temperature'] = pd.to_numeric( df_sin['max_temperature'], errors='coerce')\n",
    "df_sin['solar_exposure'] = pd.to_numeric( df_sin['solar_exposure'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin = df_sin[df_sin['max_temperature'] >= df_sin['min_temperature']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_filtered.columns.to_list()\n",
    "excluded_columns = ['Day', 'Month', 'Year', 'school_day']\n",
    "for col in columns:\n",
    "    if col not in excluded_columns:    \n",
    "        print('\\n', col, '\\n\\nReal ranges: ',  ' min ', df_filtered[col].min(), ' max ', df_filtered[col].max(),\n",
    "              '\\nSynthetic ranges: ', ' min ', df_sin[col].min(), ' max ', df_sin[col].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin = df_sin[df_sin['demand'] >= 50000]\n",
    "df_sin = df_sin[df_sin['demand'] <= 200653.84]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered['RRP'] <= 400]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA confront between synthetic and real values\n",
    "\n",
    "Here we have a first sight to the continue variables marginal distributions of both the real and synthetic data, in order to check that the model has been able to catch the main properties of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot = ['RRP',\n",
    " 'min_temperature',\n",
    " 'max_temperature',\n",
    " 'solar_exposure',\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, col in enumerate(cols_to_plot):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.histplot(data=df_filtered, x=col, label='Real', alpha=0.8,edgecolor='black', kde=False)\n",
    "    sns.histplot(data=df_sin, x=col, color='red', alpha=0.5, label='Synthetic', edgecolor='black', kde=False)\n",
    "    if col == 'RRP':\n",
    "        plt.xlim(-10, 300)\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = df_filtered.copy()\n",
    "df_synthetic = df_sin.copy()\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "kl_divergences = {}\n",
    "\n",
    "for column in cols_to_plot:\n",
    "    real_hist, _ = np.histogram(df_real[column], bins=50, density=True)\n",
    "    synth_hist, _ = np.histogram(df_synthetic[column], bins=50, density=True)\n",
    "    \n",
    "    real_hist = real_hist + 1e-10\n",
    "    synth_hist = synth_hist + 1e-10\n",
    "    \n",
    "    real_hist = real_hist / np.sum(real_hist)\n",
    "    synth_hist = synth_hist / np.sum(synth_hist)\n",
    "    \n",
    "    kl_div = kl_divergence(real_hist, synth_hist)\n",
    "    kl_divergences[column] = kl_div\n",
    "\n",
    "print(\"KL Divergences:\")\n",
    "for column, kl_div in kl_divergences.items():\n",
    "    print(f\"{column}: {kl_div:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check the temporal properties of the data we set the timestamp back to the original format, so that the models can handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['Date'] = pd.to_datetime(df_filtered[['Year', 'Month', 'Day']])\n",
    "df_filtered = df_filtered.drop(columns=['Day', 'Month', 'Year'])\n",
    "\n",
    "df_sin['Date'] = pd.to_datetime(df_sin[['Year', 'Month', 'Day']])\n",
    "df_sin = df_sin.drop(columns=['Day', 'Month', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(2, 2, figsize=(17, 15))\n",
    "\n",
    "ax1 = ax[0]\n",
    "ax2 = ax[1]\n",
    "\n",
    "ax1[0].plot(df_filtered['Date'].iloc[0:1000], df_filtered['RRP'].iloc[0:1000], label='Original')\n",
    "ax1[0].plot(df_sin['Date'].iloc[0:1000], df_sin['RRP'].iloc[0:1000], color='red', alpha=0.5, label='Synthetic')\n",
    "ax1[0].set_xlabel(\"Date\")\n",
    "ax1[0].set_ylabel(\"Number of RRP\")\n",
    "ax1[0].legend()\n",
    "\n",
    "ax1[1].plot(df_filtered['Date'].iloc[0:1000], df_filtered['demand'].iloc[0:1000], label='Original')\n",
    "ax1[1].plot(df_sin['Date'].iloc[0:1000], df_sin['demand'].iloc[0:1000], color='red', alpha=0.5,label='Synthetic')\n",
    "ax1[1].set_xlabel(\"Date\")\n",
    "ax1[1].set_ylabel(\"Number of demand\")\n",
    "ax1[1].legend()\n",
    "\n",
    "ax2[0].plot(df_filtered['Date'].iloc[0:1000], df_filtered['max_temperature'].iloc[0:1000], label='Original')\n",
    "ax2[0].plot(df_sin['Date'].iloc[0:1000], df_sin['max_temperature'].iloc[0:1000], color='red', alpha=0.5,label='Synthetic')\n",
    "ax2[0].set_xlabel(\"Date\")\n",
    "ax2[0].set_ylabel(\"Number of First max_temperature\")\n",
    "ax2[0].legend()\n",
    "\n",
    "ax2[1].plot(df_filtered['Date'].iloc[0:1000], df_filtered['solar_exposure'].iloc[0:1000], label='Original')\n",
    "ax2[1].plot(df_sin['Date'].iloc[0:1000], df_sin['solar_exposure'].iloc[0:1000], color='red', alpha=0.5,label='Synthetic')\n",
    "ax2[1].set_xlabel(\"Date\")\n",
    "ax2[1].set_ylabel(\"Number of solar_exposure\")\n",
    "ax2[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = df_filtered.drop(columns=['Date', 'school_day'])\n",
    "df_synthetic = df_sin.drop(columns=['Date', 'school_day'])\n",
    "\n",
    "max_lag = 2\n",
    "autocorrelations = {}\n",
    "\n",
    "for column in df_real.columns:\n",
    "    real_acf = acf(df_real[column], nlags=max_lag)\n",
    "    synth_acf = acf(df_synthetic[column], nlags=max_lag)\n",
    "    \n",
    "    autocorrelations[column] = {\n",
    "        'real': real_acf,\n",
    "        'synthetic': synth_acf\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"\\nAutocorrelations:\")\n",
    "for column, acfs in autocorrelations.items():\n",
    "    print(f\"\\n{column}:\")\n",
    "    print(\"Lag\\tReal\\tSynthetic\")\n",
    "    for lag in range(max_lag + 1):\n",
    "        print(f\"{lag}\\t{acfs['real'][lag]:.4f}\\t{acfs['synthetic'][lag]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We now evaluate the quality of the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copied values\n",
    "\n",
    "First of all we'd like to have an insight on the synthetic data row-wise, we check if row by row there are copied values of the real data and, if there, how many they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equals(df1, df2, col_to_drop=[]):\n",
    "\n",
    "    df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "    df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "    \n",
    "    matching_df1 = df1[df1['Date'].isin(df2['Date'])].copy()\n",
    "    matching_df2 = df2[df2['Date'].isin(df1['Date'])].copy()\n",
    "    original_indices = matching_df2.index\n",
    "    \n",
    "    matching_df1 = matching_df1.sort_values(by='Date').reset_index(drop=True)\n",
    "    matching_df2 = matching_df2.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "    matching_df1 = matching_df1.drop(columns=col_to_drop)\n",
    "    matching_df2 = matching_df2.drop(columns=col_to_drop)\n",
    "\n",
    "    \n",
    "    \n",
    "    numeric_cols = matching_df1.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    results = []\n",
    "    columns_matched = []\n",
    "    summary_counter = Counter()\n",
    "    matched_indices = []\n",
    "\n",
    "    for i in range(len(matching_df1)):\n",
    "        common_values = (matching_df1.loc[i, numeric_cols] == matching_df2.loc[i, numeric_cols])\n",
    "        count_common = common_values.sum()\n",
    "        matched_columns = numeric_cols[common_values].tolist()\n",
    "        \n",
    "        results.append(count_common)\n",
    "        columns_matched.append(matched_columns)\n",
    "        \n",
    "        summary_counter.update(matched_columns)\n",
    "        \n",
    "        if count_common > 0:\n",
    "            matched_indices.append({'index': original_indices[i], 'matched_columns': matched_columns})\n",
    "\n",
    "    summary_report = dict(summary_counter)\n",
    "\n",
    "    return results, columns_matched, summary_report, matched_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, _, report, _ = compute_equals(df_filtered, df_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences = pd.Series(distances).value_counts().sort_index()/len(distances) *100\n",
    "\n",
    "plt.figure(figsize=(12, 6), dpi=300)\n",
    "ax = occurrences.plot(kind='bar', color='#1f77b4', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Number of matching values', fontsize=14)\n",
    "plt.ylabel('Percentage of rows', fontsize=14)\n",
    "plt.title('Percentage of matching values between corresponding rows of real and synthetic datasets', fontsize=16, pad=20)\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.1f}%\", \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='center', \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points',\n",
    "                fontsize=12,\n",
    "                color='black')\n",
    "\n",
    "plt.ylim(0, 105)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Report of Copied Variables:\\n\")\n",
    "for variable, value in report.items():\n",
    "    print(f\"{variable.replace('_', ' ').capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "Another useful analysis can be conducted by implementing a ML discriminator that tries to detect synthetic data, in order to evaluate if these present any pattern that a ML model could find. We then implmented a RandomForest classifier, the datasets have been first labeled as `Real: 0` or `Synthetic: 1`, then merged and shuffled. On the merged dataset a static train-test-split has been applied and the classifier has been first trained and the tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(real_data, synth_data):\n",
    "    \n",
    "    real_data['Synthetic'] = 0\n",
    "\n",
    "    synth_data['Synthetic'] = 1\n",
    "    \n",
    "    combined_data = pd.concat([real_data, synth_data], axis=0)\n",
    "    \n",
    "    shuffled_df = combined_data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    X = shuffled_df.drop('Synthetic', axis=1)\n",
    "    y = shuffled_df['Synthetic']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['school_day'] = df_filtered['school_day'].map({'Y': 1, 'N': 0})\n",
    "df_sin['school_day'] = df_sin['school_day'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = df_filtered.drop(['Date'], axis=1)\n",
    "df_S = df_sin.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator(df_F, df_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance to the closest record (DCR)\n",
    "\n",
    "To quantify the similarity between synthetic data and original data, we use a distance to closest record (DCR) calculation. This method involves two steps:\n",
    "\n",
    "1. **Calculating the Euclidean Distance for Original Data**: For each datapoint in the original dataset, we calculate the Euclidean distance to its nearest neighbor within the same dataset.\n",
    "\n",
    "2. **Calculating the Euclidean Distance for Synthetic Data**: For each synthetic datapoint, we calculate the Euclidean distance to the closest datapoint in the original dataset.\n",
    "\n",
    "A greater synthetic-real DCR indicates that the synthetic datapoint is more distinct from the real datapoint, suggesting higher privacy since re-identification is more difficult. Conversely, a synthetic-real DCR close to 0 means that the synthetic datapoint closely resembles a real datapoint, offering little to no privacy protection.\n",
    "\n",
    "Interpreting synthetic-real DCRs can be challenging because synthetic data points are designed to fall within the same range as the original data, increasing the likelihood of proximity to a real record. To address this, we compare the distribution of distances between synthetic records and real records with the distribution of distances among real records themselves. If the synthetic data is similar or farther from the real data compared to the real data's internal distances, it implies that the synthetic data provides good privacy privacy and is not merely a copy or simple perturbation of the real data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dcr_optimized(real_df, synthetic_df):\n",
    "\n",
    "    real_distances = cdist(real_df.values, real_df.values)\n",
    "    np.fill_diagonal(real_distances, np.inf)\n",
    "    \n",
    "    synthetic_to_real_distances = cdist(synthetic_df.values, real_df.values)\n",
    "    \n",
    "\n",
    "    real_dcr = np.min(real_distances, axis=1)\n",
    "    \n",
    "    synthetic_dcr = np.min(synthetic_to_real_distances, axis=1)\n",
    "    \n",
    "    return real_dcr, synthetic_dcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dcr_o, synthetic_dcr_o = compute_dcr_optimized(df_F, df_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_values = synthetic_dcr_o[synthetic_dcr_o < 90]\n",
    "sv = real_dcr_o[real_dcr_o < 90]\n",
    "synth_median = np.median(selected_values)\n",
    "real_median = np.median(sv)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(sv, bins = 50 ,alpha=0.5, label='Real DCR')\n",
    "plt.hist(selected_values, bins = 50 ,alpha=0.5, label='Synthetic DCR')\n",
    "\n",
    "plt.axvline(synth_median, color='red', linestyle='dashed', linewidth=2, label=f'Synthetic Median: {synth_median:.2f}')\n",
    "plt.axvline(real_median, color='black', linestyle='dashed', linewidth=2, label=f'Real Median: {real_median:.2f}')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning efficiency (MLE)\n",
    "\n",
    "As last we try to build a simple machine learning model on the data to compare the efficiency of synthetic data with respect to the real. To do this we **train** a model on the synthetic data and test it on the real, in order to verify how efficient the synthetic data would be. We then compare the accuraxcy of the model with the one of a model trained and testd on the real data. As model we use a simple ``RandomForest`` classifier, using as target variable ``schoolday``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12\n",
    "\n",
    "X_s = df_sin.drop(['school_day', 'Date'], axis=1)\n",
    "y_s = df_sin['school_day']\n",
    "\n",
    "X = df_filtered.drop(['school_day', 'Date'], axis=1)\n",
    "y = df_filtered['school_day']\n",
    "\n",
    "smote = SMOTE(random_state=seed)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "X_s_resampled, y_s_resampled = smote.fit_resample(X_s, y_s)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=seed)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "rf.fit(X_s_resampled, y_s_resampled)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "print('======= Random Forest - SYNTHETIC train REAL test =======')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('                     Accuracy: ',round(accuracy_score(y_test, predictions),2),'\\n')\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "print('======= Random Forest - REAL train REAL test =======')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('                     Accuracy: ',round(accuracy_score(y_test, predictions),2),'\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
